{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_from_scratch_chapter5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 곱셈계층 구현\n",
        "\n",
        "class MulLayer:\n",
        "  def __init__(self): # 인스턴스 변수 x,y 초기화\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "\n",
        "  def forward(self, x, y): # 순전파\n",
        "    self.x = x # 입력한 x값으로 설정\n",
        "    self.y = y # 입력한 y값으로 설정\n",
        "    out = x * y # x와 y를 곱해서 출력\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout): # 역전파\n",
        "    dx = dout * self.y # 상류에서 미분한 값과 순전파 때 x였기 때문에 서로 바꿔서 y를 곱함\n",
        "    dy = dout * self.x # 상류에서 미분한 값과 순전파 때 y였기 때문에 서로 바꿔서 x를 곱함\n",
        "    return dx, dy"
      ],
      "metadata": {
        "id": "QXKjc4K5EN9k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple = 100\n",
        "apple_num = 2\n",
        "tax = 1.1\n",
        "\n",
        "# 계층\n",
        "mul_apple_layer = MulLayer() # 위에서 생성한 MulLayer()로 설정\n",
        "mul_tax_layer = MulLayer() # 위에서 생성한 MulLayer()로 설정\n",
        "\n",
        "# 순전파\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num) # 사과 가격을 사과의 원가와 개수를 MulLayer의 순전파 적용\n",
        "price = mul_tax_layer.forward(apple_price, tax) # 순전파를 적용한 사과가격과 택스를 MulLayer의 순전파 적용\n",
        "\n",
        "print(price)\n",
        "print('-'*20)\n",
        "\n",
        "# 역전파\n",
        "dprice = 1 # 역전파의 처음 시작은 1\n",
        "dapple_price, dtax = mul_tax_layer.backward(dprice) # dprice를 역전파를 통해서 하류의 dapple_price와 dtax를 적용\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price) # 상류에서 계산된 dapple_price를 역전파를 통해서 하류의 dapple, dapple_num를 적용\n",
        "\n",
        "print(dapple, dapple_num, tax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vod8-36BfxBK",
        "outputId": "d73c6028-7375-488b-d757-9c2c33919873"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220.00000000000003\n",
            "--------------------\n",
            "2.2 110.00000000000001 1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 덧셈계층 구현\n",
        "\n",
        "class AddLayer:\n",
        "  def __init__(self): # 덧셈 계층에는 초기화가 필요하지 않기 때문에 Pass\n",
        "    pass\n",
        "  \n",
        "  def forward(self, x, y): # 순전파\n",
        "    out = x + y # 입력된 x,y를 더해서 출력\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout): # 역전파\n",
        "    dx = dout * 1 # 상류에서 미분한 값으로 하류로 보냄\n",
        "    dy = dout * 1 # 상류에서 미분한 값으로 하류로 보냄\n",
        "    return dx, dy"
      ],
      "metadata": {
        "id": "v2Yxt00QglUC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple = 100\n",
        "apple_num = 2\n",
        "orange = 150\n",
        "orange_num = 3\n",
        "tax = 1.1\n",
        "\n",
        "# 계층\n",
        "mul_apple_layer = MulLayer() # 위에서 생성한 MulLayer()로 설정\n",
        "mul_orange_layer = MulLayer() # 위에서 생성한 MulLayer()로 설정\n",
        "add_apple_orange_layer = AddLayer() # 위에서 생성한 AddLayer()로 설정\n",
        "mul_tax_layer = MulLayer() # 위에서 생성한 MulLayer()로 설정\n",
        "\n",
        "# 순전파\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)  # 사과 가격을 사과의 원가와 개수를 MulLayer의 순전파 적용\n",
        "orange_price = mul_orange_layer.forward(orange, orange_num) # 오렌지 가격을 오렌지의 원가와 개수를 MulLayer의 순전파 적용\n",
        "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # 사과 가격과 오렌지 가격을 AddLayer의 순전파 적용\n",
        "price = mul_tax_layer.forward(all_price, tax)  # 순전파를 적용한 사과가격, 오렌지가격과 택스를 MulLayer의 순전파 적용\n",
        "\n",
        "# 역전파\n",
        "dprice = 1 # 역전파의 처음 시작은 1\n",
        "dall_price, dtax = mul_tax_layer.backward(dprice) # dprice를 역전파를 통해서 하류의 dall_price와 dtax를 적용\n",
        "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) # dall_price를 역전파를 통해서 하류의 dapple_price와 dorange_price를 적용\n",
        "dorange, dorange_num = mul_orange_layer.backward(dorange_price) # dorange_price를 역전파를 통해서 하류의 dorange와 dorange_num를 적용\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price) # dapple_price를 역전파를 통해서 하류의 dapple와 dapple_num를 적용\n",
        "\n",
        "print(price)\n",
        "print(dapple_num, dapple, dorange, dorange_num, dtax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGWIqGsnsfyI",
        "outputId": "bc8ade7d-8e12-4dc6-84e7-f9fd5b6af0ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "715.0000000000001\n",
            "110.00000000000001 2.2 3.3000000000000003 165.0 650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReLU함수식\n",
        "\n",
        "#$h(x) = \\begin{cases} x \\ (x>0)\\\\ 0 \\ (x\\leq0) \\end{cases}$\n",
        "\n",
        "\n",
        "\n",
        "# ReLU 미분식\n",
        "\n",
        "# $\\frac{\\delta{y}}{\\delta{x}} = \\begin{cases} 1 \\ (x>0)\\\\ 0 \\ (x\\leq0) \\end{cases}$"
      ],
      "metadata": {
        "id": "21LhuO6w48Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU함수 구현\n",
        "\n",
        "class Relu:\n",
        "  def __init__(self):\n",
        "    self.mask = None # mask 인스턴스 변수 초기화\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.mask = (x<=0) # x의 원소 값이 0 이하인 인덱스는 True, 그외는 False\n",
        "    out = x.copy() # 출력은 x의 값을 복사\n",
        "    out[self.mask] = 0 # 입력 값이 0 이하면 역전파 때의 값은 0으로 설정\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dout[self.mask] = 0 # 순전파때 만들어둔 mask를 써서 원소가 True면 상류에서 전파된 dout을 0으로 설정\n",
        "    dx = dout # x에 대한 미분으로 설정\n",
        "    return dx"
      ],
      "metadata": {
        "id": "1E7tOCKnu5B-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid 함수식\n",
        "\n",
        "#$y = \\frac{1}{1+e^{-x}}$\n",
        "\n",
        "\n",
        "# Sigmoid 미분식\n",
        "\n",
        "# $\\frac{\\delta{L}}{\\delta{y}}y^2e^{-x} = \\frac{e^{-x}}{{(1+e^{-x})}^2} = \\frac{\\delta{L}}{\\delta{y}}y(1-y)$  "
      ],
      "metadata": {
        "id": "vrMDlvJU-aZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid함수 구현\n",
        "import numpy as np\n",
        "\n",
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.out = None # 출력 초기화\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = 1 / (1 + np.exp(-x)) # sigmoid 함수식 구현\n",
        "    self.out = out\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = dout * (1.0 - self.out) * self.out # sigmoid 미분식 구현\n",
        "    return dx"
      ],
      "metadata": {
        "id": "9v7qKIYM-Hnj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 어파인 변환은 신경망의 순전파 때 수행하는 행렬의 곱을 의미\n",
        "# Affine 구현\n",
        "\n",
        "X = np.random.rand(2)\n",
        "W = np.random.rand(2,3)\n",
        "B = np.random.rand(3)\n",
        "\n",
        "print(X.shape)\n",
        "print(W.shape)\n",
        "print(B.shape)\n",
        "\n",
        "y = np.dot(X,W) + B\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dscb-dTHPvp",
        "outputId": "7dea9faa-fdc4-42e9-b664-d61a77e74672"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n",
            "(2, 3)\n",
            "(3,)\n",
            "[0.63067628 1.37393088 1.08974785]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine:\n",
        "  def __init__(self, W, b):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.x = None\n",
        "    self.dW = None\n",
        "    self.db = None\n",
        "\n",
        "  def forward(self, x): # 순전파는 행렬의 곱 연산\n",
        "    self.x = x\n",
        "    out = np.dot(x, self.W) + self.b\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dx = np.dot(dout, self.W.T) # 행렬의 미분은 역행렬로 이해\n",
        "    self.dW = np.dot(self.x.T, dout)\n",
        "    self.db = np.sum(dout, axis=0) # axis = 0은 0번째 축이므로 0번째 축의 총합\n",
        "    return dx"
      ],
      "metadata": {
        "id": "Kb06sIFpINhy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y,t):\n",
        "  if y.ndim == 1: # y의 차원이 1차원일때\n",
        "    t = t.reshape(1, t.size) # t의 사이즈로 재형상\n",
        "    y = y.reshape(1, y.size) # y의 사이즈로 재형상\n",
        "\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(t*np.log(y+1e-7)) / batch_size # 배치의 크기로 나눠 정규화하고 평균의 교차 엔트로피 오차를 계산\n",
        "\n",
        "\n",
        "def softmax(a):\n",
        "  c = np.max(a) # 오버플로 방지위해서 입력신호에서 가장 큰 수 설정\n",
        "  exp_a = np.exp(a - c) # 오버플로 방지 \n",
        "  sum_exp_a = np.sum(exp_a) # 지수함수 a의 합\n",
        "  y = exp_a / sum_exp_a # 소프트맥스 함수 구현\n",
        "  return y"
      ],
      "metadata": {
        "id": "RShFmYPDOZRF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithLoss:\n",
        "  def __init__(self): # loss, y, t 초기화\n",
        "    self.loss = None \n",
        "    self.y = None \n",
        "    self.t = None\n",
        "\n",
        "  def forward(self, x, t):\n",
        "    self.t = t\n",
        "    self.y = softmax(x) # 위에서 설정한 softmax 적용\n",
        "    self.loss = cross_entropy_error(self.y, self.t) # loss 크로스엔트로피에러 적용\n",
        "    return self.loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    batch_size = self.t.shape[0] # t의 차원수로 배치사이즈 설정\n",
        "    dx = (self.y - self.t) / batch_size # 전파하는 값을 배치로 나눠서 전파\n",
        "    return dx"
      ],
      "metadata": {
        "id": "qbJ4fFt_M1F7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch.git\n",
        "import sys, os\n",
        "sys.path.append('/content/deep-learning-from-scratch')\n",
        "from common.layers import *\n",
        "from common.gradient import numerical_gradient\n",
        "from collections import OrderedDict\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "    # 가중치 초기화\n",
        "    self.params = {}\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    # 계층 생성\n",
        "    self.layers = OrderedDict() # 순서가 있는 딕셔너리\n",
        "    self.layers['Affien1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "    self.layers['Relu1'] = Relu()\n",
        "    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "    self.lastLayer = SoftmaxWithLoss()\n",
        "\n",
        "  def predict(self, x):\n",
        "    for layer in self.layers.values():\n",
        "      x = layer.forward(x)\n",
        "    return x\n",
        "\n",
        "  # x:입력, t:정답레이블\n",
        "\n",
        "  def loss(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    return self.lastLayer.forward(y,t)\n",
        "\n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    if t.nidm != 1 : t = np.argmax(t, axis=1)\n",
        "    accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "    return accuracy\n",
        "\n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "    grads = {}\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "    return grads\n",
        "\n",
        "  def gradient(self, x, t):\n",
        "    # 순전파\n",
        "    self.loss(x, t)\n",
        "\n",
        "    # 역전파\n",
        "    dout = 1\n",
        "    dout = self.lastLayer.backward(dout)\n",
        "\n",
        "    layers = list(self.layers.values())\n",
        "    layers.reverse()\n",
        "    for layer in layers:\n",
        "      dout = layer.backward(dout)\n",
        "    \n",
        "    # 결과 저장\n",
        "    grads = {}\n",
        "    grads['W1'] = self.layers['Affine1'].dW\n",
        "    grads['b1'] = self.layers['Affine1'].dW\n",
        "    grads['W2'] = self.layers['Affine2'].dW\n",
        "    grads['b2'] = self.layers['Affine2'].dW\n",
        "    return grads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVIEk-4-QVad",
        "outputId": "1b09aee8-9a39-4755-bf4e-efe1e8eee264"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 826, done.\u001b[K\n",
            "remote: Total 826 (delta 0), reused 0 (delta 0), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (826/826), 52.21 MiB | 44.26 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset.mnist import load_mnist\n",
        "from ch05.two_layer_net import TwoLayerNet\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "x_batch = x_train[:3]\n",
        "t_batch = t_train[:3]\n",
        "\n",
        "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
        "grad_backprop = network.gradient(x_batch, t_batch)\n",
        "\n",
        "# 가중치의 차이의 절댓값을 구한후 그 절댓값들의 평균\n",
        "for key in grad_numerical.keys():\n",
        "  diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
        "  print(key + ':' + str(diff))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDSJkaXqX-eY",
        "outputId": "1af9ca85-9fa5-45aa-b651-9771f4a6d8db"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1:5.281659582144946e-10\n",
            "b1:3.266011442445548e-09\n",
            "W2:6.907127359673907e-09\n",
            "b2:1.4092849031088762e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset.mnist import load_mnist\n",
        "from ch05.two_layer_net import TwoLayerNet\n",
        "\n",
        "# 데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10) # 입력 784개, 히든층 50개, 출력 10개\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0] # x_train의 차원수만큼 크기 설정\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1) # train_size를 batch_size로 나눈 값의 최댓값으로 에포크 설정\n",
        "\n",
        "for i in range(iters_num):\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "\n",
        "  grad = network.gradient(x_batch, t_batch) # 오차역전파로 기울기 설정\n",
        "\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'): # lr과 기울기로 params 갱신\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss) # 구한 loss값을 리스트화\n",
        "\n",
        "  if i % iter_per_epoch == 0: # 에폭이 0이 될때까지\n",
        "    train_acc = network.accuracy(x_train, t_train)\n",
        "    test_acc = network.accuracy(x_test, t_test)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(train_acc, test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8k_hXIYZyC0",
        "outputId": "d4dbed55-e289-490e-e318-c44166ad44eb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15003333333333332 0.1544\n",
            "0.9044 0.907\n",
            "0.92175 0.9248\n",
            "0.9361166666666667 0.9367\n",
            "0.9441 0.9438\n",
            "0.9521333333333334 0.9511\n",
            "0.9572166666666667 0.9546\n",
            "0.9605166666666667 0.9555\n",
            "0.9632833333333334 0.9609\n",
            "0.9643666666666667 0.9608\n",
            "0.9675 0.963\n",
            "0.9701833333333333 0.9652\n",
            "0.9717166666666667 0.9663\n",
            "0.9726333333333333 0.9671\n",
            "0.9745166666666667 0.9668\n",
            "0.9753166666666667 0.9691\n",
            "0.9769666666666666 0.9702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2egNpYJTdAmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}